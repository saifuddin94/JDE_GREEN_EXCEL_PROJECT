{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fd1d4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import sqlalchemy\n",
    "\n",
    "import nltk\n",
    "import re  \n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e12d3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First apply for twitter developer account to retrieve your credentials such as consumer key \n",
    "# and secret as well as your access token key and secret\n",
    "\n",
    "# Credentials\n",
    "\n",
    "consumer_key = 'frxFyJskSPkPvxiMu8NKUfvX8'\n",
    "\n",
    "consumer_secret = 'tCtujcAsHIZF8TSzDxKCBJbfM75v8vNEzClmuA48nSqpnC0PH0'\n",
    "\n",
    "access_token = '557446265-KT2R47ApGYDLiLMDjbYTQONxhctzAtdhbZRm39SE'\n",
    "\n",
    "access_token_secret = 'nYaLC8D3KzHPcKCRNIoNclAEiMDZ5mROmCqpZZsyheAxb'\n",
    "\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "786b226d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>939091</th>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>Washington, DC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_name        location\n",
       "user_id                           \n",
       "939091   Joe Biden  Washington, DC"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second, figure out the data information you want to scrape from Twitter. \n",
    "# After that, categorise theminto different tables. \n",
    "# For Green Excel, we have decided to split the data information into three tables. \n",
    "# Table One will be profile_info.\n",
    "\n",
    "\n",
    "# This is the information we want to have inside profile_info table.\n",
    "\n",
    "user_id = []\n",
    "user_name = []\n",
    "location = []\n",
    "\n",
    "# Put in all of the screen name from the profile you want to scrape in a list form.\n",
    "\n",
    "name = ['JoeBiden']\n",
    "\n",
    "# Then iterate i inside the name list and append in the list above. \n",
    "# Using the api.get_user to retrieve data for our DataFrame\n",
    "\n",
    "for i in name:\n",
    "    user = api.get_user(i)\n",
    "    user_id.append(user.id_str)\n",
    "    user_name.append(user.name)\n",
    "    location.append(user.location)\n",
    "    \n",
    "#Manipulate the list into dataframe. And Set your index with your primary key.\n",
    "    \n",
    "profile_info = pd.DataFrame({'user_id': user_id, 'user_name': user_name, 'location': location})\n",
    "profile_info = profile_info.set_index('user_id')\n",
    "profile_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "893f9c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>followers_count</th>\n",
       "      <th>following_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>screen_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>JoeBiden</th>\n",
       "      <td>31340998</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             followers_count  following_count\n",
       "screen_name                                  \n",
       "JoeBiden            31340998               48"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Table two will be social_network_info\n",
    "\n",
    "# This is the information we want to have inside social_network_info table.\n",
    "\n",
    "screen_name = []\n",
    "followers_count = []\n",
    "following_count = []\n",
    "\n",
    "# Put in all of the screen name from the profile you want to scrape in a list form.\n",
    "\n",
    "name = ['JoeBiden']\n",
    "\n",
    "# Then iterate i inside the name list and append in the list above.\n",
    "\n",
    "for i in name:\n",
    "    user = api.get_user(i)\n",
    "    screen_name.append(user.screen_name)\n",
    "    followers_count.append(user.followers_count)\n",
    "    following_count.append(user.friends_count)\n",
    "    \n",
    "# Manipulate the list into dataframe. And Set your index with your primary key.\n",
    "    \n",
    "social_network_info = pd.DataFrame({'screen_name': screen_name, 'followers_count': followers_count,\n",
    "                                    'following_count': following_count})\n",
    "\n",
    "social_network_info = social_network_info.set_index('screen_name')\n",
    "social_network_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4b7c573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the db\n",
    "# Password will be your Postgresql server password\n",
    "pgcon = psycopg2.connect(\n",
    "        host = 'localhost',\n",
    "        user = 'postgres',\n",
    "        password = 'bida123')\n",
    "\n",
    "pgcursor = pgcon.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4fe1ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ISOLATION_LEVEL_AUTOCOMMIT from psycopg2 extensions to lock the server \n",
    "# so that you can create the database\n",
    "\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "\n",
    "# To create Interim Project Database and set isolation level to autocommit\n",
    "\n",
    "pgcon.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "\n",
    "# Create the database\n",
    "\n",
    "pgcursor.execute('DROP DATABASE IF EXISTS interim_project')\n",
    "pgcursor.execute('CREATE DATABASE interim_project')\n",
    "\n",
    "pgcon.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bc2a48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the server with the db name created\n",
    "\n",
    "pgcon = psycopg2.connect(\n",
    "        host = 'localhost',\n",
    "        database = 'interim_project',\n",
    "        user = 'postgres',\n",
    "        password = 'bida123')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9a2eacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import create_engine from sqlalchemy\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Using engine to connect to the database in PostgreSQL\n",
    "engine = create_engine('postgresql+psycopg2://postgres:bida123@localhost/interim_project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0b5ba31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.cursor.LegacyCursorResult at 0x1bcdd322a30>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use .tosql to load your pd DataFrame(profile_info) into your postgreSQL\n",
    "\n",
    "profile_info.to_sql('profile_info', engine, if_exists='replace', index = True)\n",
    "\n",
    "# Change your column datatype\n",
    "\n",
    "engine.execute('ALTER TABLE profile_info ALTER COLUMN user_id TYPE int USING user_id :: integer')\n",
    "engine.execute('ALTER TABLE profile_info ALTER COLUMN user_name TYPE varchar(255)')\n",
    "engine.execute('ALTER TABLE profile_info ALTER COLUMN location TYPE varchar(255)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b51b517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.cursor.LegacyCursorResult at 0x1bcdd37b4c0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use .tosql to load your pd DataFrame(social_network_info) into your postgreSQL\n",
    "\n",
    "social_network_info.to_sql('social_network_info', engine, if_exists='replace', index = True)\n",
    "\n",
    "# Change your column datatype\n",
    "\n",
    "engine.execute('ALTER TABLE social_network_info ALTER COLUMN screen_name TYPE varchar(255)')\n",
    "engine.execute('ALTER TABLE social_network_info ALTER COLUMN followers_count TYPE int USING followers_count :: integer')\n",
    "engine.execute('ALTER TABLE social_network_info ALTER COLUMN following_count TYPE int USING following_count :: integer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775b9b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table Three will be the tweet_data.\n",
    "\n",
    "# We started by finding out the 'root-level' attribute in the data dictionary and deciding on what attribute to extract.\n",
    "\n",
    "for i in tweepy.Cursor(api.user_timeline, id=\"JoeBiden\", tweet_mode=\"extended\").items(1):\n",
    "    print(dir(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e65448a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using tweet data dictionary documentation, we decided on the relevant attribute to extract for table 3.\n",
    "\n",
    "number_of_tweets = 1000\n",
    "tweet_id = []\n",
    "tweets = []\n",
    "like_count = []\n",
    "time = []\n",
    "retweet_count = []\n",
    "source = []\n",
    "\n",
    "# Using pandas package, we create a dataframe with attribute as our column header. tweet_id will be the primary key.\n",
    "\n",
    "for i in tweepy.Cursor(api.user_timeline, screen_name='JoeBiden', tweet_mode = 'extended').items(number_of_tweets):\n",
    "    tweet_id.append(i.id)\n",
    "    tweets.append(i.full_text)\n",
    "    like_count.append(i.favorite_count)\n",
    "    time.append(i.created_at)\n",
    "    retweet_count.append(i.retweet_count)\n",
    "    source.append(i.source)\n",
    "    \n",
    "df = pd.DataFrame({'tweet_id': tweet_id, 'tweets': tweets, 'like_count': like_count, \n",
    "                   'time': time, 'retweet_count': retweet_count, 'source': source})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541b4a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean dataframe by removing tweets that contains \"RT\" as these are retweets from Joe Biden's POTUS account (same messages repeated in both Joe Biden's personal and OOTUS account)\n",
    "\n",
    "df = df[~df.tweets.str.contains(\"RT\")]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6011fbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searching for number of tweets that contain both keywords.\n",
    "\n",
    "z = df[(df.tweets.str.contains('jobs')) | (df.tweets.str.contains('economy'))]\n",
    "\n",
    "len(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7e6413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe for tweets with both keywords\n",
    "\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e126a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to find the top keywords, we need to split the sentences to individual words so that we can count the number of times that individual words appears\n",
    "\n",
    "list_of_sentences = [sentence for sentence in df.tweets]\n",
    "\n",
    "lines=[]\n",
    "\n",
    "for sentence in list_of_sentences:\n",
    "    words = sentence.split()\n",
    "    for w in words:\n",
    "        lines.append(w)\n",
    "\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d98cbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex library is used here to define a special string to represent a pattern to be matched in a search operation (defining filter expression) \n",
    "# The filter expression used here will replace the character with a \" \" (space) for all those characters that are not A-Z,a-z,0-9\n",
    "# Using for loop, if the word is not \" \", we append the word to our list so that punctuations are removed\n",
    "\n",
    "lines = [re.sub(r'[^A-Za-z0-9]+', '', x) for x in lines]\n",
    "\n",
    "lines\n",
    "\n",
    "lines2 = []\n",
    "\n",
    "for word in lines:\n",
    "    if word != '':\n",
    "        lines2.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc18f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk is a natural language toolkit, from nltk, import Snowball Stemmer\n",
    "# Snowball Stemmer allows us to extract words based on their root (e.g. runner, ran, running will be extracted as run which is the root word)\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "# The Snowball Stemmer requires that you pass a language parameter\n",
    "s_stemmer = SnowballStemmer(language='english')\n",
    "\n",
    "stem = []\n",
    "for word in lines2:\n",
    "    stem.append(s_stemmer.stem(word))\n",
    "    \n",
    "stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a82163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing all Stop Words which are repeated several times (e.g. a, the, etc)\n",
    "# Reason: stop words has no meaning by itself and we are looking for keywords\n",
    "\n",
    "stem2 = []\n",
    "\n",
    "for word in stem:\n",
    "    if word not in nlp.Defaults.stop_words:\n",
    "        stem2.append(word)\n",
    "\n",
    "stem2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59b7798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting individual words into dataframe\n",
    "# value_counts function is to count number of times each word appear, to be used in visualisation later\n",
    "\n",
    "df = pd.DataFrame(stem2)\n",
    "\n",
    "df = df[0].value_counts()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36befa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a plot that shows the top 20 words being used\n",
    "\n",
    "df = df[:20,]\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "x=df.values \n",
    "y=df.index\n",
    "data = pd.DataFrame({'x': x, 'y': y})\n",
    "\n",
    "sns.barplot(x = 'x', y = 'y', alpha=0.8, data=data)\n",
    "\n",
    "plt.title('Top Words Overall')\n",
    "plt.ylabel('Word from Tweet', fontsize=12)\n",
    "plt.xlabel('Count of Words', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ec7fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spacy is used to break the words into categories such as people, places, organisation.\n",
    "# Import displacy from spacy to obtain visualizer of category.\n",
    "# Import counter from collections to keeps track of how many times equivalent values are added.\n",
    "\n",
    "from spacy import displacy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac92ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to be used in the organisation chart later\n",
    "\n",
    "def show_ents(doc):\n",
    "    if doc.ents:\n",
    "        for ent in doc.ents:\n",
    "            print(ent.text + ' - ' + ent.label_ + ' - ' + str(spacy.explain(ent.label_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe35c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codes to get top 20 organisation\n",
    "\n",
    "str1 = \" \" \n",
    "stem2 = str1.join(lines2)\n",
    "\n",
    "stem2 = nlp(stem2)\n",
    "\n",
    "label = [(X.text, X.label_) for X in stem2.ents]\n",
    "\n",
    "df6 = pd.DataFrame(label, columns = ['Word','Entity'])\n",
    "\n",
    "df7 = df6.where(df6['Entity'] == 'ORG')\n",
    "\n",
    "df7 = df7['Word'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5359859f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the chart for the top 20 organisation\n",
    "\n",
    "df = df7[:20,]\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(df.values, df.index, alpha=0.8)\n",
    "plt.title('Top Organizations Mentioned')\n",
    "plt.ylabel('Word from Tweet', fontsize=12)\n",
    "plt.xlabel('Count of Words', fontsize=12)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
